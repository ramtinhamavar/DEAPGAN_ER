{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b6eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras import backend \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107f50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and Hyper-parameters\n",
    "batch_size = 32\n",
    "num_channels = 3\n",
    "num_classes_of_each_cat = 10\n",
    "num_classes = 4*num_classes_of_each_cat\n",
    "image_height = 128\n",
    "image_width = 320\n",
    "latent_dim = 128\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "critic_in_channels = num_channels + num_classes\n",
    "PARTIAL_IMG_SHAPE = (128, 8, critic_in_channels)\n",
    "IMG_SHAPE = (128, 320, critic_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "raw_files_addr = \"DEAP_Dataset/data_preprocessed_python/\"\n",
    "transformed_files_addr = \"DEAP_Dataset/transformed_data/\"\n",
    "file_names = os.listdir(raw_files_addr)\n",
    "\n",
    "def trial_file_processor(file_addr, trial):\n",
    "    \n",
    "    channel_stft_size = (128, 8)\n",
    "    start_points_list = list()\n",
    "    number_of_windows = 3\n",
    "    window_length = 10\n",
    "    start_points_list = [[3, 3+window_length, 3+2*window_length],\n",
    "                        [33, 33+window_length, 33+2*window_length]]\n",
    "\n",
    "    with open(file_addr, 'rb') as file:\n",
    "        subject_file = pickle.load(file, encoding='latin1')    \n",
    "    \n",
    "    max_after_normalize = 1\n",
    "    min_after_normalize = 0 \n",
    "\n",
    "    color_channel_stft = None\n",
    "    full_norm_stft = np.zeros(shape=(len(start_points_list),channel_stft_size[0], 40*channel_stft_size[1], 3))\n",
    "    \n",
    "    start_point_number = 0\n",
    "    for start_points in start_points_list:\n",
    "        for color_channel in range(0, 3):\n",
    "            for channel in range(0, 40):\n",
    "                stft = librosa.stft(subject_file[\"data\"][trial, channel,\n",
    "                                              128*(start_points[color_channel]):128*(start_points[color_channel]+window_length)],\n",
    "                                              n_fft=256, hop_length=125)\n",
    "                stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "                norm_stft = (stft_db - stft_db.min())/(stft_db.max() - stft_db.min())\n",
    "                norm_stft = norm_stft*(max_after_normalize - min_after_normalize) + min_after_normalize\n",
    "                norm_stft = cv2.resize(norm_stft, (channel_stft_size[1], channel_stft_size[0]))\n",
    "                if color_channel_stft is None:\n",
    "                    color_channel_stft = norm_stft\n",
    "                else:\n",
    "                    color_channel_stft = np.append(color_channel_stft, norm_stft, axis=1)\n",
    "                    \n",
    "            full_norm_stft[start_point_number, : , :, color_channel] = color_channel_stft\n",
    "            color_channel_stft = None\n",
    "            \n",
    "        start_point_number = start_point_number + 1\n",
    "        \n",
    "    return full_norm_stft, np.array(subject_file[\"labels\"][trial])\n",
    "\n",
    "\n",
    "for file_name in file_names:\n",
    "    subject_name = file_name.split(\".\")[0]\n",
    "    for trial in range(0, 40):\n",
    "        data, labels = trial_file_processor(raw_files_addr+file_name, trial)\n",
    "        for sample in range(0, data.shape[0]):\n",
    "            data_label_dict = {\"data\":data[sample], \"labels\":labels}\n",
    "            with open(transformed_files_addr+subject_name+\"t\"+str(trial)+\"s\"+str(sample), 'wb') as handle:\n",
    "                pickle.dump(data_label_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_files_addr = \"DEAP_Dataset/transformed_data/\"\n",
    "generated_files_addr = \"generated_data/singleGenModel/\"\n",
    "with open(transformed_files_addr+\"s01t4s0\", 'rb') as handle:\n",
    "    test = pickle.load(handle)\n",
    "\n",
    "with open(generated_files_addr+\"gen_10\", 'rb') as handle:\n",
    "    gen = pickle.load(handle)\n",
    "    \n",
    "\n",
    "#plt.imshow(test[\"data\"])\n",
    "print(type(test[\"data\"]))\n",
    "print(test[\"labels\"])\n",
    "plt.imshow(gen[\"data\"])\n",
    "print(type(gen[\"data\"]))\n",
    "print(gen[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc09a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "transformed_files_addr = \"DEAP_Dataset/transformed_data/\"\n",
    "\n",
    "def train_test_spliter(addr, train_ratio, val_ratio):\n",
    "    \n",
    "    files = os.listdir(addr)\n",
    "    number_of_files = len(files)\n",
    "    random.shuffle(files)\n",
    "    end_of_train_files = math.floor(train_ratio*number_of_files)\n",
    "    train_files = files[0:end_of_train_files]\n",
    "    validation_files = files[end_of_train_files:end_of_train_files+math.floor(val_ratio*number_of_files)]\n",
    "    test_files = files[end_of_train_files+math.floor(val_ratio*number_of_files):]\n",
    "    \n",
    "    return train_files, validation_files, test_files\n",
    "    \n",
    "\n",
    "class DEAPDataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_addrs, feature_files_addr, batch_size=32):\n",
    "        self.files_addrs = files_addrs\n",
    "        self.feature_files_addr = feature_files_addr\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def number_of_samples(self):\n",
    "        return len(self.files_addrs)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.files_addrs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_files_addrs = self.files_addrs[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        batch_data, batch_labels = self.__data_generation(batch_files_addrs)\n",
    "\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    \n",
    "\n",
    "    def __data_generation(self, batch_file_addrs):\n",
    "        batch_data = list()\n",
    "        batch_labels = list()\n",
    "\n",
    "        for batch_file_addr in batch_file_addrs:\n",
    "            with open(self.feature_files_addr+batch_file_addr, 'rb') as handle:\n",
    "                loaded_data = pickle.load(handle)\n",
    "                batch_data.append((loaded_data[\"data\"].astype(\"float32\")*2.0)-1.0)\n",
    "                labels = np.reshape(np.round(loaded_data[\"labels\"]), (4, 1))\n",
    "                labels = keras.utils.to_categorical(labels, 10)\n",
    "                batch_labels.append(labels.astype(\"float32\"))\n",
    "\n",
    "        return (np.array(batch_data), np.array(batch_labels)) \n",
    "    \n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "train_files, validation_files, test_files = train_test_spliter(transformed_files_addr, train_ratio, val_ratio)\n",
    "\n",
    "train_gen = DEAPDataGenerator(train_files, transformed_files_addr)\n",
    "validation_gen = DEAPDataGenerator(validation_files, transformed_files_addr)\n",
    "test_gen = DEAPDataGenerator(test_files, transformed_files_addr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76482d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train files\n",
    "src_address = \"DEAP_Dataset/transformed_data/\"\n",
    "dst_address = \"generated_data/singleGenModel/\"\n",
    "#dst_address = \"E:/Hamavar/proposal/generated_data/randomNoiseGenModel/\"\n",
    "for file_name in train_files:\n",
    "    shutil.copyfile(src_address+file_name, dst_address+file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61387a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "def conv_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"same\",\n",
    "    use_bias=True,\n",
    "    use_bn=False,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.5,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_partial_critic_model(input_layer):\n",
    "    img_input = input_layer\n",
    "    \n",
    "    x = conv_block(\n",
    "        img_input,\n",
    "        64,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        use_bias=True,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        128,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=True,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        256,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=True,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "    x = conv_block(\n",
    "        x,\n",
    "        512,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_critic_model(number_of_partial_critics):\n",
    "    partial_critics_input_list = list()\n",
    "    partial_critics_concatted = None\n",
    "    \n",
    "    critic_input = layers.Input(shape=IMG_SHAPE)\n",
    "    \n",
    "    partial_critics_input_list = tf.split(critic_input, num_or_size_splits=number_of_partial_critics, axis=2)\n",
    "    \n",
    "    for critic_index in range(number_of_partial_critics):\n",
    "        partial_critic_input = partial_critics_input_list[critic_index]\n",
    "        if partial_critics_concatted is None:\n",
    "            partial_critics_concatted = get_partial_critic_model(partial_critic_input)\n",
    "        else:\n",
    "            partial_critics_concatted = tf.keras.layers.Concatenate()([partial_critics_concatted,\n",
    "                                                                       get_partial_critic_model(partial_critic_input)])\n",
    "     \n",
    "    x = conv_block(\n",
    "        partial_critics_concatted,\n",
    "        512,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(2, 2),\n",
    "        use_bn=False,\n",
    "        activation=layers.LeakyReLU(0.2),\n",
    "        use_bias=True,\n",
    "        use_dropout=False,\n",
    "        drop_value=0.3,\n",
    "    )   \n",
    "    \n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    \n",
    "    c_model = keras.models.Model(critic_input, x, name=\"partial_critic\")\n",
    "    return c_model\n",
    "    \n",
    "\n",
    "def upsample_block(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(2, 2),\n",
    "    up_size=(2, 2),\n",
    "    padding=\"same\",\n",
    "    use_bn=False,\n",
    "    use_bias=True,\n",
    "    use_dropout=False,\n",
    "    drop_value=0.3,\n",
    "):\n",
    "    x = layers.UpSampling2D(up_size)(x)\n",
    "    x = layers.Conv2DTranspose(\n",
    "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
    "    )(x)\n",
    "\n",
    "    if use_bn:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    if use_dropout:\n",
    "        x = layers.Dropout(drop_value)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_partial_generator_model(input_layer):\n",
    "    \n",
    "    x = upsample_block(\n",
    "        input_layer,\n",
    "        128,\n",
    "        layers.LeakyReLU(0.2),\n",
    "        strides=(1, 1),\n",
    "        use_bias=False,\n",
    "        use_bn=True,\n",
    "        padding=\"same\",\n",
    "        use_dropout=False,\n",
    "    )\n",
    "    x = upsample_block(\n",
    "        x,\n",
    "        128,\n",
    "        layers.LeakyReLU(0.2),\n",
    "        strides=(1, 1),\n",
    "        use_bias=False,\n",
    "        use_bn=True,\n",
    "        padding=\"same\",\n",
    "        use_dropout=False,\n",
    "    )\n",
    "    x = upsample_block(\n",
    "        x, 128, layers.LeakyReLU(0.2), strides=(1, 1), padding=\"same\", use_bias=False, use_bn=True, use_dropout=False\n",
    "    )\n",
    "    \n",
    "    x = upsample_block(\n",
    "        x, 128, layers.LeakyReLU(0.2), strides=(1, 1), padding=\"same\", use_bias=False, use_bn=True, use_dropout=False\n",
    "    )\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_generator_model(number_of_partial_generators):\n",
    "    partial_generators_output_list = list()\n",
    "    \n",
    "    noise = layers.Input(shape=(generator_in_channels,))\n",
    "    x = layers.Dense(16 * 40 * 256, use_bias=False)(noise)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Reshape((16, 40, 256))(x)\n",
    "    for generator_index in range(number_of_partial_generators):\n",
    "        partial_generators_output_list.append(get_partial_generator_model(x))\n",
    "    \n",
    "    concatted_layer = tf.keras.layers.Concatenate(axis=3)(partial_generators_output_list)\n",
    "    output_layer = layers.Conv2D(3, (2, 2), strides=(1, 1), padding=\"same\", activation=layers.Activation(\"tanh\"))(concatted_layer)\n",
    "    \n",
    "    g_model = keras.models.Model(noise, output_layer, name=\"generator\")\n",
    "    return g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b62e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_model_T():\n",
    "    partial_critics_input_list = list()\n",
    "    partial_critics_concatted = None\n",
    "    critic_input = layers.Input(shape=IMG_SHAPE)\n",
    "    \n",
    "    critic = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(critic_input)\n",
    "    critic = tf.keras.layers.LeakyReLU(alpha=0.2)(critic)\n",
    "    \n",
    "    critic = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(critic)\n",
    "    critic = tf.keras.layers.LeakyReLU(alpha=0.2)(critic)\n",
    "    \n",
    "    critic = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(critic)\n",
    "    critic = tf.keras.layers.LeakyReLU(alpha=0.2)(critic)\n",
    "    \n",
    "    critic = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(critic)\n",
    "    critic = tf.keras.layers.LeakyReLU(alpha=0.2)(critic)\n",
    "    \n",
    "    critic = tf.keras.layers.Flatten()(critic)\n",
    "    critic = tf.keras.layers.Dropout(0.4)(critic)\n",
    "    critic = tf.keras.layers.Dense(1)(critic)\n",
    "    \n",
    "    c_model = keras.models.Model(critic_input, critic)\n",
    "    \n",
    "    return c_model\n",
    "\n",
    "\n",
    "def get_generator_model_T():\n",
    "    \n",
    "    noise = layers.Input(shape=(generator_in_channels,))\n",
    "    x = layers.Dense(4 * 10 * 512, use_bias=False)(noise)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Reshape((4, 10, 512))(x)\n",
    "    \n",
    "    gen = tf.keras.layers.Conv2DTranspose(512, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = tf.keras.layers.Conv2DTranspose(256, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(gen)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = tf.keras.layers.Conv2DTranspose(128, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(gen)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = tf.keras.layers.Conv2DTranspose(128, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(gen)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = tf.keras.layers.Conv2DTranspose(128, kernel_size=(4, 4), strides=(2, 2), padding=\"same\")(gen)\n",
    "    gen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Conv2D(3, kernel_size=(7, 7), activation='tanh', padding=\"same\")(gen)\n",
    "    \n",
    "    g_model = keras.models.Model(noise, output_layer, name=\"generator\")\n",
    "    \n",
    "    return g_model\n",
    "\n",
    "\n",
    "critic = get_critic_model_T()\n",
    "generator = get_generator_model_T()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1860df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 168)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20480)             3440640   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 20480)            81920     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 20480)             0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 10, 512)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 8, 20, 512)       4194816   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 8, 20, 512)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 16, 40, 256)      2097408   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 16, 40, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 32, 80, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 32, 80, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 64, 160, 128)     262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 64, 160, 128)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 128, 320, 128)    262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 128, 320, 128)     0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, 320, 3)       18819     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,882,563\n",
      "Trainable params: 10,841,603\n",
      "Non-trainable params: 40,960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ce65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalWGAN(keras.Model):\n",
    "    def __init__(self, critic, generator, latent_dim, critic_extra_steps=3, gp_weight=10.0):\n",
    "        super(ConditionalWGAN, self).__init__()\n",
    "        self.critic = critic\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.critic_loss_tracker = keras.metrics.Mean(name=\"critic_loss\")\n",
    "        self.critic_extra_steps = critic_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.critic_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, critic_loss_fn, generator_loss_fn):\n",
    "        super(ConditionalWGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.critic_loss_fn = critic_loss_fn\n",
    "        self.generator_loss_fn = generator_loss_fn\n",
    "        \n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\"Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.critic(interpolated)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "    \n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "        #print(real_images.shape)\n",
    "        #print(one_hot_labels.shape)\n",
    "        #(None, 28, 56, 1)\n",
    "        #(None, 2, 10)\n",
    "        #Before\n",
    "        #(None, 28, 28, 1)\n",
    "        #(None, 10)\n",
    "        one_hot_labels = tf.cast(one_hot_labels, tf.float32)\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the critic.\n",
    "        valence_one_hot_labels = one_hot_labels[:, 0, :, None, None] # adds two extra dimension at the end\n",
    "        valence_one_hot_labels = tf.repeat(\n",
    "            valence_one_hot_labels, repeats=[image_height * image_width]\n",
    "        )\n",
    "        valence_one_hot_labels = tf.reshape(\n",
    "            valence_one_hot_labels, (-1, image_height, image_width, num_classes_of_each_cat)\n",
    "        ) # (none, 28, 28, 10)\n",
    "        \n",
    "        arousal_one_hot_labels = one_hot_labels[:, 1, :, None, None] # adds two extra dimension at the end\n",
    "        arousal_one_hot_labels = tf.repeat(\n",
    "            arousal_one_hot_labels, repeats=[image_height * image_width]\n",
    "        )\n",
    "        \n",
    "        arousal_one_hot_labels = tf.reshape(\n",
    "            arousal_one_hot_labels, (-1, image_height, image_width, num_classes_of_each_cat)\n",
    "        ) # (none, 28, 28, 10)\n",
    "        \n",
    "        dominance_one_hot_labels = one_hot_labels[:, 2, :, None, None] # adds two extra dimension at the end\n",
    "        dominance_one_hot_labels = tf.repeat(\n",
    "            dominance_one_hot_labels, repeats=[image_height * image_width]\n",
    "        )\n",
    "        dominance_one_hot_labels = tf.reshape(\n",
    "            dominance_one_hot_labels, (-1, image_height, image_width, num_classes_of_each_cat)\n",
    "        ) # (none, 28, 28, 10)\n",
    "        \n",
    "        liking_one_hot_labels = one_hot_labels[:, 3, :, None, None] # adds two extra dimension at the end\n",
    "        liking_one_hot_labels = tf.repeat(\n",
    "            liking_one_hot_labels, repeats=[image_height * image_width]\n",
    "        )\n",
    "        liking_one_hot_labels = tf.reshape(\n",
    "            liking_one_hot_labels, (-1, image_height, image_width, num_classes_of_each_cat)\n",
    "        ) # (none, 28, 28, 10)\n",
    "        \n",
    "        image_one_hot_labels = tf.concat(\n",
    "            [valence_one_hot_labels, arousal_one_hot_labels, dominance_one_hot_labels, liking_one_hot_labels], axis=-1\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, tf.reshape(one_hot_labels, (-1, num_classes))], axis=1\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the critic.\n",
    "        for i in range(self.critic_extra_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            random_vector_labels = tf.concat(\n",
    "                [random_latent_vectors, tf.reshape(one_hot_labels, (-1, num_classes))], axis=1\n",
    "            )\n",
    "            generated_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "            combined_images = tf.concat(\n",
    "                [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = self.critic(combined_images)\n",
    "                \n",
    "                gp = self.gradient_penalty(batch_size, real_image_and_labels, fake_image_and_labels)\n",
    "                d_cost = self.critic_loss_fn(labels, predictions)\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "            grads = tape.gradient(d_loss, self.critic.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(grads, self.critic.trainable_weights)\n",
    "            )\n",
    "\n",
    "            \n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, tf.reshape(one_hot_labels, (-1, num_classes))], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the critic)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            fake_images_predictions = self.critic(fake_image_and_labels)\n",
    "            g_loss = self.generator_loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.critic_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.critic_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    \n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=4, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        saved_images = list()\n",
    "        \n",
    "        for i in range(self.num_img):\n",
    "            \n",
    "            random_latent_vectors = tf.random.normal(shape=(1, self.latent_dim))\n",
    "            fake_labels = [random.randint(0,9), random.randint(0,9), random.randint(0,9), random.randint(0,9)]\n",
    "            fake_labels = keras.utils.to_categorical(fake_labels, 10)\n",
    "            random_vector_labels = tf.concat(\n",
    "                [random_latent_vectors, tf.reshape(fake_labels, (-1, num_classes))], axis=1\n",
    "            )\n",
    "        \n",
    "            generated_images = self.model.generator(random_vector_labels)\n",
    "            generated_images = (generated_images + 1.0) / 2.0\n",
    "            \n",
    "            saved_images.append(generated_images[0])\n",
    "        \n",
    "\n",
    "        for i in range(self.num_img):\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(saved_images[i])\n",
    "        \n",
    "        plt.savefig(f\"generated_img_{epoch}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "#Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "cond_gan = ConditionalWGAN(\n",
    "    critic=critic, generator=generator, latent_dim=latent_dim, critic_extra_steps=3)\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),\n",
    "    critic_loss_fn = critic_loss,\n",
    "    generator_loss_fn=generator_loss, #keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "cbk = GANMonitor(num_img=4, latent_dim=latent_dim)\n",
    "\n",
    "cond_gan.fit(train_gen, epochs=1000, callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20610fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.models.load_model('savedModels/singleGenModel.h5')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors = tf.random.normal(shape=(1, 128))\n",
    "#fake_labels = np.round([2 ,2 ,2 ,5])\n",
    "fake_labels = [random.random()*9 ,random.random()*9 ,random.random()*9 ,random.random()*9]\n",
    "fake_labels = np.round(fake_labels)\n",
    "print(fake_labels)\n",
    "fake_labels = keras.utils.to_categorical(fake_labels, 10)\n",
    "random_vector_labels = tf.concat(\n",
    "        [random_latent_vectors, tf.reshape(fake_labels, (-1, num_classes))], axis=1\n",
    "    )\n",
    "        \n",
    "generated_images = generator(random_vector_labels)\n",
    "generated_images = (generated_images + 1.0) / 2.0\n",
    "plt.imshow(generated_images[0])\n",
    "print(generated_images[0].shape)\n",
    "print(fake_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895521d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fake Data\n",
    "generated_data_files = \"generated_data/singleGenModel/\" \n",
    "\n",
    "number_of_generated_data = 3*len(train_files) \n",
    "for index in range(number_of_generated_data):\n",
    "    fake_labels = [random.random()*9 ,random.random()*9 ,random.random()*9 ,random.random()*9]\n",
    "    fake_labels = np.round(fake_labels, decimals=2)\n",
    "    fake_labels_cat = np.round(fake_labels)\n",
    "    fake_labels_cat = keras.utils.to_categorical(fake_labels, 10)\n",
    "    random_latent_vectors = tf.random.normal(shape=(1, 128))\n",
    "    random_vector_labels = tf.concat(\n",
    "        [random_latent_vectors, tf.reshape(fake_labels_cat, (-1, num_classes))], axis=1\n",
    "    )\n",
    "    generated_images = generator(random_vector_labels)\n",
    "    generated_images = np.array(generated_images)\n",
    "    generated_images = (generated_images + 1.0) / 2.0\n",
    "    \n",
    "    \n",
    "    data_label_dict = {\"data\":generated_images[0], \"labels\":fake_labels}\n",
    "    with open(generated_data_files+\"gen_\"+str(index), 'wb') as handle:\n",
    "        pickle.dump(data_label_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fake data by random noise\n",
    "generated_data_files = \"generated_data/randomNoiseGenModel/\" \n",
    "raw_files_addr = \"DEAP_Dataset/data_preprocessed_python/\"\n",
    "file_names = train_files\n",
    "\n",
    "number_of_generated_data = 3*len(train_files) \n",
    "\n",
    "def add_noise_to_trials(files_addr, file_name):\n",
    "    \n",
    "    channel_stft_size = (128, 8)\n",
    "    start_points_list = list()\n",
    "    number_of_windows = 3\n",
    "    window_length = 10\n",
    "    offset = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    subject_number = file_name[0:3]\n",
    "    sample_number = file_name[-1]\n",
    "    trial_number = int(file_name[-3:-2])\n",
    "    \n",
    "    with open(files_addr+subject_number+\".dat\", 'rb') as file:\n",
    "        subject_file = pickle.load(file, encoding='latin1')    \n",
    "    \n",
    "    subject_data = subject_file[\"data\"][trial_number]\n",
    "    subject_label = subject_file[\"labels\"][trial_number]\n",
    "    \n",
    "    \n",
    "    if sample_number == 0:\n",
    "        offset = 3\n",
    "    elif sample_number == 1:\n",
    "        offset = 33\n",
    "    \n",
    "    start_points_list = [[offset, offset+window_length, offset+2*window_length]]\n",
    "    \n",
    "    \n",
    "    noise = np.random.normal(0,1,subject_data.shape[0]*subject_data.shape[1])\n",
    "    noise = noise.reshape(subject_data.shape[0], subject_data.shape[1])\n",
    "    \n",
    "    subject_data = subject_data + noise\n",
    "    \n",
    "    max_after_normalize = 1\n",
    "    min_after_normalize = 0 \n",
    "\n",
    "    color_channel_stft = None\n",
    "    full_norm_stft = np.zeros(shape=(len(start_points_list),channel_stft_size[0], 40*channel_stft_size[1], 3))\n",
    "    \n",
    "    start_point_number = 0\n",
    "    for start_points in start_points_list:\n",
    "        for color_channel in range(0, 3):\n",
    "            for channel in range(0, 40):\n",
    "                stft = librosa.stft(subject_data[channel,\n",
    "                                              128*(start_points[color_channel]):128*(start_points[color_channel]+window_length)],\n",
    "                                              n_fft=256, hop_length=125)\n",
    "                stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "                norm_stft = (stft_db - stft_db.min())/(stft_db.max() - stft_db.min())\n",
    "                norm_stft = norm_stft*(max_after_normalize - min_after_normalize) + min_after_normalize\n",
    "                norm_stft = cv2.resize(norm_stft, (channel_stft_size[1], channel_stft_size[0]))\n",
    "                if color_channel_stft is None:\n",
    "                    color_channel_stft = norm_stft\n",
    "                else:\n",
    "                    color_channel_stft = np.append(color_channel_stft, norm_stft, axis=1)\n",
    "                    \n",
    "            full_norm_stft[start_point_number, : , :, color_channel] = color_channel_stft\n",
    "            color_channel_stft = None\n",
    "            \n",
    "        start_point_number = start_point_number + 1\n",
    "        \n",
    "    return full_norm_stft, np.array(subject_label)\n",
    "\n",
    "\n",
    "for index in range(number_of_generated_data):\n",
    "    file_name = file_names[np.random.randint(0, len(file_names))]\n",
    "    data, labels = add_noise_to_trials(raw_files_addr, file_name)\n",
    "    for sample in range(0, data.shape[0]):\n",
    "        data_label_dict = {\"data\":data[sample], \"labels\":labels}\n",
    "        with open(generated_data_files+\"noiseAdded\"+\"_\"+str(index), 'wb') as handle:\n",
    "            pickle.dump(data_label_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator model data generator\n",
    "estimator_train_files_addr = \"generated_data/randomNoiseGenModel/\"\n",
    "\n",
    "estimator_train_files = os.listdir(estimator_train_files_addr)\n",
    "random.shuffle(train_files)\n",
    "\n",
    "class DEAPDataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_addrs, feature_files_addr, batch_size=32):\n",
    "        self.files_addrs = files_addrs\n",
    "        self.feature_files_addr = feature_files_addr\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def number_of_samples(self):\n",
    "        return len(self.files_addrs)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.files_addrs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_files_addrs = self.files_addrs[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        batch_data, batch_labels = self.__data_generation(batch_files_addrs)\n",
    "\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    \n",
    "\n",
    "    def __data_generation(self, batch_file_addrs):\n",
    "        batch_data = list()\n",
    "        batch_labels = list()\n",
    "\n",
    "        for batch_file_addr in batch_file_addrs:\n",
    "            with open(self.feature_files_addr+batch_file_addr, 'rb') as handle:\n",
    "                loaded_data = pickle.load(handle)\n",
    "                batch_data.append((loaded_data[\"data\"].astype(\"float32\")*2.0)-1.0)\n",
    "                batch_labels.append(loaded_data[\"labels\"])\n",
    "\n",
    "        return (np.array(batch_data), np.array(batch_labels)) \n",
    "    \n",
    "\n",
    "\n",
    "estimator_train_gen = DEAPDataGenerator(estimator_train_files, estimator_train_files_addr)\n",
    "estimator_validation_gen = DEAPDataGenerator(validation_files, transformed_files_addr)\n",
    "estimator_test_gen = DEAPDataGenerator(test_files, transformed_files_addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator_model():\n",
    "    input_layer = keras.Input(shape=(128, 320, 3))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(16, kernel_size=(5, 11), padding=\"same\", activation=\"relu\")(input_layer)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(8, kernel_size=(3, 3), padding=\"same\",activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(4, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.1)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.1)(x)\n",
    "    x = tf.keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(rate=0.1)(x)\n",
    "    x = tf.keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(units=4)(x)\n",
    "\n",
    "    estimator_model = tf.keras.models.Model(input_layer, x)\n",
    "    estimator_model.compile(loss='mae', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005)) # tf.keras.optimizers.Adam(learning_rate=0.007)\n",
    "\n",
    "    return estimator_model\n",
    "\n",
    "estimator_model = get_estimator_model()\n",
    "estimator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f3c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = estimator_model.fit(estimator_train_gen, validation_data=estimator_validation_gen, epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6155f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(Model, generator):\n",
    "    predicted_labels = np.zeros(shape=(generator.number_of_samples(), 4))\n",
    "    true_labels = np.zeros(shape=(generator.number_of_samples(), 4))\n",
    "\n",
    "    counter = 0\n",
    "    for data, labels in generator:\n",
    "        predicted = Model.predict(data)\n",
    "    \n",
    "        predicted_labels[counter*batch_size:(counter+1)*batch_size, :] = predicted\n",
    "        true_labels[counter*batch_size:(counter+1)*batch_size, :] = labels\n",
    "        counter = counter + 1\n",
    "        \n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "\n",
    "def accuracy_evaluation_percentage(true_labels, predicted_labels):\n",
    "    labels_dimension = 4\n",
    "    false_predictions = np.zeros(shape=(1, labels_dimension))\n",
    "    total_numbers_of_test_samples = len(predicted_labels)\n",
    "    \n",
    "    for prd_idx in range(0, total_numbers_of_test_samples):\n",
    "        for label_idx in range(0, labels_dimension):\n",
    "            if ((predicted_labels[prd_idx, label_idx]>5) and (true_labels[prd_idx, label_idx]<5)) or \\\n",
    "            ((predicted_labels[prd_idx, label_idx]<5) and (true_labels[prd_idx, label_idx]>5)):\n",
    "                false_predictions[0, label_idx] = false_predictions[0, label_idx] + 1\n",
    "\n",
    "    return ((total_numbers_of_test_samples - false_predictions)/total_numbers_of_test_samples)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_hist.history['loss'])\n",
    "plt.plot(train_hist.history['val_loss'])\n",
    "\n",
    "true_labels, predicted_labels = predict_labels(estimator_model, estimator_test_gen)\n",
    "accuracy_evaluation = accuracy_evaluation_percentage(true_labels, predicted_labels)\n",
    "print(accuracy_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df36d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_files = \"E:/Hamavar/proposal/generated_data/singleGenModel/\" \n",
    "train_files = os.listdir(generated_data_files)\n",
    "random.shuffle(train_files)\n",
    "estimator_train_gen = DEAPDataGenerator(train_files, generated_data_files)\n",
    "estimator_model = get_estimator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = estimator_model.fit(estimator_train_gen, validation_data=estimator_validation_gen, epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_hist.history['loss'])\n",
    "plt.plot(train_hist.history['val_loss'])\n",
    "true_labels, predicted_labels = predict_labels(estimator_model, test_gen)\n",
    "accuracy_evaluation = accuracy_evaluation_percentage(true_labels, predicted_labels)\n",
    "print(accuracy_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74838573",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_files = \"E:/Hamavar/proposal/generated_data/randomNoiseGenModel/\" \n",
    "train_files = os.listdir(generated_data_files)\n",
    "random.shuffle(train_files)\n",
    "train_gen = DEAPDataGenerator(train_files, generated_data_files)\n",
    "estimator_model = get_estimator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d68ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = estimator_model.fit(train_gen, validation_data=validation_gen, epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f44aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_hist.history['loss'])\n",
    "plt.plot(train_hist.history['val_loss'])\n",
    "true_labels, predicted_labels = predict_labels(estimator_model, test_gen)\n",
    "accuracy_evaluation = accuracy_evaluation_percentage(true_labels, predicted_labels)\n",
    "print(accuracy_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
